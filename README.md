# üîÆ K8s-Prophet-Autoscaler : Infrastructure Auto-R√©paratrice par IA

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![Kubernetes](https://img.shields.io/badge/Kubernetes-Minikube-326ce5?style=for-the-badge&logo=kubernetes)
![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-e6522c?style=for-the-badge&logo=prometheus)
![Prophet](https://img.shields.io/badge/AI-Time%20Series%20Forecasting-important?style=for-the-badge)

> **"L'autoscaling classique r√©agit √† la douleur. L'autoscaling par IA l'emp√™che."**

## ‚ö° Le Concept (AIOps)

Les Autoscalers Kubernetes standards sont **r√©actifs** : ils attendent que l'utilisation du CPU d√©passe un seuil (ex: 80%) pour ajouter des r√©pliques. Cela cr√©e une p√©riode de latence o√π les utilisateurs subissent des lenteurs ou des erreurs 503 pendant le d√©marrage des nouveaux pods.

**Ce projet impl√©mente un autoscaler PROACTIF.**
En utilisant le Machine Learning (Facebook Prophet) pour analyser les mod√®les de trafic en temps r√©el, le syst√®me pr√©dit les pics de charge *avant* qu'ils ne surviennent et dimensionne l'infrastructure √† l'avance.

**R√©sultat :** Scaling sans latence et optimisation des ressources.

---

## üì∏ D√©mo

![Autoscaling en Action](images/grafana.png)
*Ici nous avons utilis√© Grafana pour visualiser la consommation CPU de notre cluster K8s en temps r√©el.*

![Autoscaling en Action](images/prediction.png)
*Notre IA (Prophet) pr√©dit en bleu la courbe que va prendre notre charge CPU, en se basant sur l'historique des points noirs (donn√©es r√©elles).*

![Autoscaling en Action](images/diminue.png)

*Le syst√®me prend des d√©cisions autonomes : ici, il anticipe une baisse ou une hausse et ajuste le nombre de r√©pliques (pods) instantan√©ment.*

---

## üèóÔ∏è Architecture Technique

```mermaid
graph TD
    User[Utilisateurs / G√©n√©rateur de Trafic] -->|Requ√™tes HTTP| LB[Service K8s]
    LB --> Pods[Pods Applicatifs (Flask API)]
    
    subgraph "Couche d'Observabilit√©"
        Pods -->|Expose M√©triques| Prom[Prometheus]
        Prom -->|Scraping toutes les 15s| AI[üß† Autoscaler IA (Python)]
    end
    
    subgraph "Moteur de D√©cision"
        AI -->|1. R√©cup. Historique| Pandas[Traitement Data]
        Pandas -->|2. Entra√Ænement Mod√®le| Prophet[Facebook Prophet]
        Prophet -->|3. Pr√©diction Futur| Forecast[Calcul de Charge]
        Forecast -->|4. Ordre de Scaling| K8sAPI[API Kubernetes]
    end
    
    K8sAPI -->|Scale Up/Down| Pods
```

### La Stack
* **App Cible :** Une API Flask conteneuris√©e con√ßue pour consommer du CPU (endpoint `/stress`).
* **Monitoring :** Prometheus (via Helm kube-prometheus-stack).
* **Le Cerveau :** Script Python utilisant :
    * `prometheus-api-client` pour l'ingestion de donn√©es.
    * `prophet` pour la pr√©vision de s√©ries temporelles.
    * `kubernetes` (client python) pour l'orchestration du cluster.

---

## üöÄ Fonctionnement (La Logique)

Le syst√®me fonctionne sur une boucle de r√©troaction continue :

1.  **Ingestion :** Extrait les 30 derni√®res minutes de `container_cpu_usage` depuis Prometheus.
    * *Strat√©gie :* Utilise `sum(rate(...))` pour suivre la Charge Globale.
2.  **Entra√Ænement :** Entra√Æne un mod√®le Prophet √† la vol√©e pour d√©tecter les vagues.
3.  **Pr√©diction :** Estime la charge CPU totale requise pour la minute suivante.
4.  **D√©cision :** Calcule le nombre de r√©pliques n√©cessaires.
    
    $$\text{R√©pliques} = \lceil \frac{\text{CPU Total Pr√©dit}}{\text{CPU Cible par Pod}} \rceil$$

5.  **Action :** Applique directement le patch au D√©ploiement Kubernetes via l'API.

---

## üõ†Ô∏è Installation & Usage

### Pr√©-requis
* Docker & Minikube
* Python 3.10+
* Helm

### 1. D√©ployer l'Infrastructure
```bash
minikube start
eval $(minikube docker-env)
cd app-model
docker build -t fake-app:v1 ./app-fake
cd ..
kubectl apply -f k8s-fake.yaml
```

### 2. Installer le Monitoring
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install monitoring prometheus-community/kube-prometheus-stack
kubectl port-forward svc/monitoring-kube-prometheus-prometheus 9090:9090
```

### 3. Activer l'Autoscaler IA
```bash
cd ai-model
pip install -r requirements.txt
python autoscaler.py
```